{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsgn7XI_-nRa"
      },
      "outputs": [],
      "source": [
        "import cv2, mediapipe as mp, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "#пути\n",
        "csv_path    = Path(r\"C:\\Users\\user\\Desktop\\validation\\val_annotations.csv\")\n",
        "video_dir   = (\"C:\\Users\\user\\Desktop\\validation\")    # здесь лежат видеофайлы\n",
        "features_dir= (\"C:\\Users\\user\\Desktop\\validation\\features)\"\n",
        "features_dir.mkdir(exist_ok=True)\n",
        "\n",
        "#инициализируем Holistic\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic    = mp_holistic.Holistic(static_image_mode=False)\n",
        "\n",
        "#читаем CSV и проходим по каждому клипу\n",
        "df = pd.read_csv(csv_path)\n",
        "for _, row in df.iterrows():\n",
        "    vid_path = video_dir/row[\"clip_id\"]\n",
        "    cap      = cv2.VideoCapture(str(vid_path))\n",
        "    seq = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        rgb    = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        res    = holistic.process(rgb)\n",
        "        lm     = []\n",
        "        for pts, cnt in [(res.pose_landmarks,33),\n",
        "                         (res.left_hand_landmarks,21),\n",
        "                         (res.right_hand_landmarks,21)]:\n",
        "            if pts:\n",
        "                lm += [c for lmpt in pts.landmark for c in (lmpt.x,lmpt.y,lmpt.z)]\n",
        "            else:\n",
        "                lm += [0.0]*(3*cnt)\n",
        "        seq.append(lm)\n",
        "    cap.release()\n",
        "    arr = np.array(seq, dtype=np.float32)      # shape = (T, 225)\n",
        "    np.save(features_dir/row[\"clip_id\"].replace(\".mp4\",\".npy\"), arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Параметры\n",
        "csv_path     = Path(r\"C:\\Users\\user\\Desktop\\validation\\val_annotations.csv\")\n",
        "features_dir = csv_path.parent/\"features\"\n",
        "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Dataset\n",
        "class ClipDataset(Dataset):\n",
        "    def __init__(self, csv_file, features_dir, train=True, seq_len=32):\n",
        "        df = pd.read_csv(csv_file)\n",
        "        df = df[df[\"train\"]==train].reset_index(drop=True)\n",
        "        self.recs = df.to_dict(\"records\")\n",
        "        self.features_dir = features_dir\n",
        "        # label2idx\n",
        "        gestures = sorted(df[\"gesture\"].unique())\n",
        "        self.lab2idx = {g:i for i,g in enumerate(gestures)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.recs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rec = self.recs[idx]\n",
        "        seq = np.load(self.features_dir/rec[\"clip_id\"].replace(\".mp4\",\".npy\"))\n",
        "        # усреднить по time-axis для MLP\n",
        "        x   = seq.mean(axis=0)                     # shape=(225,)\n",
        "        y   = self.lab2idx[rec[\"gesture\"]]\n",
        "        return torch.from_numpy(x), torch.tensor(y)\n",
        "\n",
        "# лоадеры\n",
        "train_ds = ClipDataset(csv_path, features_dir, train=True)\n",
        "val_ds   = ClipDataset(csv_path, features_dir, train=False)\n",
        "tl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "vl = DataLoader(val_ds,   batch_size=32)\n",
        "\n",
        "# 3) простая MLP-модель\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, inp=225, hid=128, out=None):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(inp, hid), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(hid, out)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "model = MLP(inp=225, hid=256, out=len(train_ds.lab2idx)).to(device)\n",
        "opt   = optim.Adam(model.parameters(), lr=1e-3)\n",
        "crit  = nn.CrossEntropyLoss()\n",
        "\n",
        "#обучение (например, 10 эпох)\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total, correct = 0.0, 0\n",
        "    for x, y in tl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        out = model(x)\n",
        "        loss= crit(out, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total  += loss.item()*x.size(0)\n",
        "        correct+= (out.argmax(1)==y).sum().item()\n",
        "    print(f\"Epoch {epoch} — Loss: {total/len(train_ds):.4f}, Acc: {correct/len(train_ds):.4f}\")\n",
        "\n",
        "# валидация\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in vl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        correct += (model(x).argmax(1)==y).sum().item()\n",
        "print(f\"Val Accuracy: {correct/len(val_ds):.4f}\")\n"
      ],
      "metadata": {
        "id": "qVj9bfcz_nDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Обучение MLP и вывод ключевых метрик\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "\n",
        "train_ds = RSLGestureDataset(ANNOTATIONS_FILE, train=True)\n",
        "val_ds   = RSLGestureDataset(ANNOTATIONS_FILE, train=False)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "model = MLPClassifier(**MLP_PARAMS).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    #Тренировка\n",
        "    model.train()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out   = model(x)\n",
        "        loss  = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct    += (out.argmax(1) == y).sum().item()\n",
        "    train_loss = total_loss / len(train_ds)\n",
        "    train_acc  = correct / len(train_ds)\n",
        "\n",
        "# Валидация\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            preds = model(x).argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "    val_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} — \"\n",
        "          f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} | \"\n",
        "          f\"Val acc: {val_acc:.4f}\")\n",
        "\n",
        "# Сохраняем модель\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(f\"Модель сохранена в {MODEL_PATH}\\n\")"
      ],
      "metadata": {
        "id": "GXPAa6Y1_whp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "target_names = train_ds.labels\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.title(\"Confusion Matrix (validation)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fAYP_k7E9WDM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}